# 第2章　自编码器生成模型入门

## 2.1 生成模型简介

从要生成内容的描述指令开始，最后在转换系统的另一端得到图像。这是最简单、最非正式的**生成模型。**

正式来说，取一个特定的描述指令$(z)$，并尝试得到一个生成的样本$(x^*)$。理想情况下，$x^*$应该与真实样本$x$看起来一样真实。描述指令$z$是**潜在空间**（latent space）中的某个激励，但不会总得到相同的输出$(x^*)$。

上述第一章中的随机噪声向量通常称为**来自潜在空间的样本**。潜在空间是数据点的一种更简单的隐式表示，它用$z$表示。

## 2.2 自编码器如何用于高级场景

**自编码器**可以帮助兑数据进行自动编码，由编码器和解码器组成。通过传入概念$x$并查看他们是否能成功地以有意义的方式重现概念$x^*$，来训练他们的“自编码器”。这样就可以测量误差，这称为**重建损失($\lVert x-x^* \rVert)$)**。

**潜在空间**是数据的隐式表示。自编码器不是在未压缩的版本中表达单词或图像（例如机器学习工程师，或图像的JPEG编解码器），而是**根据对数据的理解来对其进行压缩和聚类。**

## 2.3 什么是GAN的自编码器

自编码器与GAN的关键区别：自编码器用一个损失函数对整个自编码器网络进行端到端的训练；GAN的生成器和鉴别器分别有损失函数。两者在AI图景中的范围如图2.1所示：

![图2.1]
